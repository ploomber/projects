{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe384e3",
   "metadata": {
    "papermill": {
     "duration": 0.124478,
     "end_time": "2021-10-28T01:21:54.729621",
     "exception": false,
     "start_time": "2021-10-28T01:21:54.605143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To run this locally, [install Ploomber](https://docs.ploomber.io/en/latest/get-started/quick-start.html) and execute: `ploomber examples -n guides/serialization`\n",
    "\n",
    "Found an issue? [Let us know.](https://github.com/ploomber/projects/issues/new?title=guides/serialization%20issue)\n",
    "\n",
    "Questions? [Ask us on Slack.](https://ploomber.io/community/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c2e6d",
   "metadata": {
    "papermill": {
     "duration": 0.081389,
     "end_time": "2021-10-28T01:21:54.906856",
     "exception": false,
     "start_time": "2021-10-28T01:21:54.825467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Serialization\n",
    "\n",
    "<!-- start description -->\n",
    "Tutorial explaining how the serializer and unserializer fields in a pipeline.yaml file work.\n",
    "<!-- end description -->\n",
    "\n",
    "Incremental builds allow Ploomber to skip tasks whose source code hasn't changed; each task must save their products to disk to enable such a feature. However, there are some cases when we don't want our pipeline to perform disk operations. For example, if we're going to deploy our pipeline, eliminating disk operations reduces runtime considerably.\n",
    "\n",
    "To enable a pipeline to work in both disk-based and in-memory scenarios, we can declare a `serializer` and `unzerializer` in our pipeline declaration, effectively separating our task's logic from the read/write logic.\n",
    "\n",
    "Note that this only applies to function tasks; other tasks are unaffected by the `serializer`/`unserializer` configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f036c8",
   "metadata": {
    "papermill": {
     "duration": 0.234583,
     "end_time": "2021-10-28T01:21:55.268501",
     "exception": false,
     "start_time": "2021-10-28T01:21:55.033918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Built-in pickle serialization\n",
    "\n",
    "The easiest way to get started is to use the built-in serializer and unserializer, which use the `pickle` module.\n",
    "\n",
    "Let's see an example; the following pipeline has two tasks. The first one generates a dictionary, and the second one creates two dictionaries. Since we are using the pickle-based serialization, each dictionary is saved in the pickle binary format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a240f61",
   "metadata": {
    "papermill": {
     "duration": 0.401686,
     "end_time": "2021-10-28T01:21:55.987042",
     "exception": false,
     "start_time": "2021-10-28T01:21:55.585356",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```yaml\n",
    "# Content of simple.yaml\n",
    "serializer: ploomber.io.serializer_pickle\n",
    "unserializer: ploomber.io.unserializer_pickle\n",
    "\n",
    "tasks:\n",
    "  - source: tasks.first\n",
    "    product: output/one_dict\n",
    "  \n",
    "  - source: tasks.second\n",
    "    product:\n",
    "        another: output/another_dict\n",
    "        final: output/final_dict\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc82d41",
   "metadata": {
    "papermill": {
     "duration": 0.173667,
     "end_time": "2021-10-28T01:21:56.413947",
     "exception": false,
     "start_time": "2021-10-28T01:21:56.240280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at the task's source code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad45bb",
   "metadata": {
    "papermill": {
     "duration": 0.082408,
     "end_time": "2021-10-28T01:21:56.607674",
     "exception": false,
     "start_time": "2021-10-28T01:21:56.525266",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```python\n",
    "# Content of tasks.py\n",
    "def first():\n",
    "    return dict(a=1, b=2)\n",
    "\n",
    "\n",
    "def second(upstream):\n",
    "    first = upstream['first']\n",
    "    another = dict(a=first['b'] + 1, b=first['a'] + 1)\n",
    "    final = dict(a=100, b=200)\n",
    "    return dict(another=another, final=final)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa198d",
   "metadata": {
    "papermill": {
     "duration": 0.078771,
     "end_time": "2021-10-28T01:21:56.763935",
     "exception": false,
     "start_time": "2021-10-28T01:21:56.685164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since we configured a `serializer` and `unserializer`, function tasks must `return` their outpues instead of saving them to disk in the function's body.\n",
    "\n",
    "`first` does not have any upstream dependencies and returns a dictionary. `second` has the previous task as dependency and returns two dictionaries. Note that the keys in the returned dictionary must match the names of the products declared in `pipeline.yaml` (`another`, `final`).\n",
    "\n",
    "Let's now run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232098d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:21:56.931592Z",
     "iopub.status.busy": "2021-10-28T01:21:56.930710Z",
     "iopub.status.idle": "2021-10-28T01:22:07.769849Z",
     "shell.execute_reply": "2021-10-28T01:22:07.770405Z"
    },
    "papermill": {
     "duration": 10.928295,
     "end_time": "2021-10-28T01:22:07.770723",
     "exception": false,
     "start_time": "2021-10-28T01:21:56.842428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    Ran?      Elapsed (s)    Percentage\n",
      "------  ------  -------------  ------------\n",
      "first   True         0.001281       42.9433\n",
      "second  True         0.001702       57.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building task 'second': 100%|██████████| 2/2 [00:06<00:00,  3.39s/it]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build --entry-point simple.yaml --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf265eb",
   "metadata": {
    "papermill": {
     "duration": 0.069729,
     "end_time": "2021-10-28T01:22:07.909585",
     "exception": false,
     "start_time": "2021-10-28T01:22:07.839856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The pickle format has important [security concerns](https://docs.python.org/3/library/pickle.html), **remember only to unpickle data you trust**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db170c15",
   "metadata": {
    "papermill": {
     "duration": 0.077389,
     "end_time": "2021-10-28T01:22:08.064445",
     "exception": false,
     "start_time": "2021-10-28T01:22:07.987056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom serialization logic\n",
    "\n",
    "We can also define our own serialization logic, by using the `@serializer`, and `@unserializer` decorators. Let's replicate what our pickle-based serializer/unserializer is doing as an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4bf9e",
   "metadata": {
    "papermill": {
     "duration": 0.075807,
     "end_time": "2021-10-28T01:22:08.227355",
     "exception": false,
     "start_time": "2021-10-28T01:22:08.151548",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```python\n",
    "# Content of custom.py\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from ploomber.io import serializer, unserializer\n",
    "\n",
    "\n",
    "@serializer()\n",
    "def my_pickle_serializer(obj, product):\n",
    "    Path(product).write_bytes(pickle.dumps(obj))\n",
    "\n",
    "\n",
    "@unserializer()\n",
    "def my_pickle_unserializer(product):\n",
    "    return pickle.loads(Path(product).read_bytes())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed672f0",
   "metadata": {
    "papermill": {
     "duration": 0.074659,
     "end_time": "2021-10-28T01:22:08.375200",
     "exception": false,
     "start_time": "2021-10-28T01:22:08.300541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A `@serializer` function must take two arguments: the object to serializer and the product object (taken from the task declaration). The `@unserializer` must take a single argument (the product to unserializer), and return the unserializer object.\n",
    "\n",
    "Let's modify our original pipeline to use this serializer/unserializer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf5546",
   "metadata": {
    "papermill": {
     "duration": 0.073418,
     "end_time": "2021-10-28T01:22:08.526636",
     "exception": false,
     "start_time": "2021-10-28T01:22:08.453218",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```yaml\n",
    "# Content of custom.yaml\n",
    "serializer: custom.my_pickle_serializer\n",
    "unserializer: custom.my_pickle_unserializer\n",
    "\n",
    "tasks:\n",
    "  - source: tasks.first\n",
    "    product: output/one_dict\n",
    "  \n",
    "  - source: tasks.second\n",
    "    product:\n",
    "        another: output/another_dict\n",
    "        final: output/final_dict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "007b5051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:08.676887Z",
     "iopub.status.busy": "2021-10-28T01:22:08.675964Z",
     "iopub.status.idle": "2021-10-28T01:22:20.294619Z",
     "shell.execute_reply": "2021-10-28T01:22:20.296179Z"
    },
    "papermill": {
     "duration": 11.697255,
     "end_time": "2021-10-28T01:22:20.296521",
     "exception": false,
     "start_time": "2021-10-28T01:22:08.599266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    Ran?      Elapsed (s)    Percentage\n",
      "------  ------  -------------  ------------\n",
      "first   True         0.001216       19.4342\n",
      "second  True         0.005041       80.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building task 'second': 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build --entry-point custom.yaml --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ab0ec3",
   "metadata": {
    "papermill": {
     "duration": 0.081655,
     "end_time": "2021-10-28T01:22:20.463445",
     "exception": false,
     "start_time": "2021-10-28T01:22:20.381790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom serialization logic based on the product's extension\n",
    "\n",
    "Under many circumstances, there are more suitable formats than pickle. For example, we may want to store lists or dictionaries as JSON files and other files using pickle. The `@serializer`/`@unserializer` decorators use mapping as the first argument to dispatch to different functions depending on the product's extension. Let's see an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199b285",
   "metadata": {
    "papermill": {
     "duration": 0.081722,
     "end_time": "2021-10-28T01:22:20.627903",
     "exception": false,
     "start_time": "2021-10-28T01:22:20.546181",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```python\n",
    "# Content of custom.py\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from ploomber.io import serializer, unserializer\n",
    "\n",
    "\n",
    "def write_json(obj, product):\n",
    "    Path(product).write_text(json.dumps(obj))\n",
    "\n",
    "\n",
    "def read_json(product):\n",
    "    return json.loads(Path(product).read_text())\n",
    "\n",
    "\n",
    "@serializer({'.json': write_json})\n",
    "def my_serializer(obj, product):\n",
    "    Path(product).write_bytes(pickle.dumps(obj))\n",
    "\n",
    "\n",
    "@unserializer({'.json': read_json})\n",
    "def my_unserializer(product):\n",
    "    return pickle.loads(Path(product).read_bytes())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26124daf",
   "metadata": {
    "papermill": {
     "duration": 0.076235,
     "end_time": "2021-10-28T01:22:20.788296",
     "exception": false,
     "start_time": "2021-10-28T01:22:20.712061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's modify our example pipeline. The product in the first task does not have an extension (`output/one_dict`), hence, it will use pickle-based logic. However, the tasks in the second task have a `.json` extension, and will be saved as JSON files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f839b82",
   "metadata": {
    "papermill": {
     "duration": 0.075748,
     "end_time": "2021-10-28T01:22:20.943229",
     "exception": false,
     "start_time": "2021-10-28T01:22:20.867481",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```yaml\n",
    "# Content of with-json.yaml\n",
    "serializer: custom.my_serializer\n",
    "unserializer: custom.my_unserializer\n",
    "\n",
    "tasks:\n",
    "  - source: tasks.first\n",
    "    product: output/one_dict\n",
    "  \n",
    "  - source: tasks.second\n",
    "    product:\n",
    "        another: output/another_dict.json\n",
    "        final: output/final_dict.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d1f40c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:21.111913Z",
     "iopub.status.busy": "2021-10-28T01:22:21.110790Z",
     "iopub.status.idle": "2021-10-28T01:22:31.110911Z",
     "shell.execute_reply": "2021-10-28T01:22:31.111613Z"
    },
    "papermill": {
     "duration": 10.090325,
     "end_time": "2021-10-28T01:22:31.111827",
     "exception": false,
     "start_time": "2021-10-28T01:22:21.021502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    Ran?      Elapsed (s)    Percentage\n",
      "------  ------  -------------  ------------\n",
      "first   True         0.001193       38.5834\n",
      "second  True         0.001899       61.4166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building task 'second': 100%|██████████| 2/2 [00:06<00:00,  3.26s/it]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build --entry-point with-json.yaml --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cb7bd",
   "metadata": {
    "papermill": {
     "duration": 0.083206,
     "end_time": "2021-10-28T01:22:31.272902",
     "exception": false,
     "start_time": "2021-10-28T01:22:31.189696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's print the `.json` files to verify they're not pickle files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9e0845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:31.447601Z",
     "iopub.status.busy": "2021-10-28T01:22:31.446478Z",
     "iopub.status.idle": "2021-10-28T01:22:31.528444Z",
     "shell.execute_reply": "2021-10-28T01:22:31.529088Z"
    },
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.174642,
     "end_time": "2021-10-28T01:22:31.529529",
     "exception": false,
     "start_time": "2021-10-28T01:22:31.354887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": 3, \"b\": 2}"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat output/another_dict.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6feaede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:31.732910Z",
     "iopub.status.busy": "2021-10-28T01:22:31.729672Z",
     "iopub.status.idle": "2021-10-28T01:22:31.798091Z",
     "shell.execute_reply": "2021-10-28T01:22:31.798630Z"
    },
    "papermill": {
     "duration": 0.174596,
     "end_time": "2021-10-28T01:22:31.798878",
     "exception": false,
     "start_time": "2021-10-28T01:22:31.624282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": 100, \"b\": 200}"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat output/final_dict.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66ff866",
   "metadata": {
    "papermill": {
     "duration": 0.07779,
     "end_time": "2021-10-28T01:22:31.961393",
     "exception": false,
     "start_time": "2021-10-28T01:22:31.883603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using a fallback format\n",
    "\n",
    "Since it's common to have a `fallback` serialization format, the decorators have a `fallback` argument that, when enabled, uses the `pickle` module when the product's extension does not match any of the registered ones in the first argument.\n",
    "\n",
    "The example works the same as the previous one, except we don't have to write our pickle-based logic.\n",
    "\n",
    "`fallback` can also take the [joblib](https://github.com/joblib/joblib) or [cloudpickle](https://github.com/cloudpipe/cloudpickle) values. They're similar to the pickle format but have some advantages. For example, `joblib` produces smaller files when the serialized object contains many NumPy arrays, while cloudpickle supports serialization of some objects that the pickle module doesn't. To use `fallback='joblib'` or `fallback='cloudpickle'` the corresponding module must be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ab698",
   "metadata": {
    "papermill": {
     "duration": 0.086577,
     "end_time": "2021-10-28T01:22:32.136341",
     "exception": false,
     "start_time": "2021-10-28T01:22:32.049764",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```python\n",
    "# Content of custom.py\n",
    "\n",
    "from ploomber.io import serializer, unserializer\n",
    "\n",
    "\n",
    "@serializer({'.json': write_json}, fallback=True)\n",
    "def my_fallback_serializer(obj, product):\n",
    "    pass\n",
    "\n",
    "\n",
    "@unserializer({'.json': read_json}, fallback=True)\n",
    "def my_fallback_unserializer(product):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1796b4",
   "metadata": {
    "papermill": {
     "duration": 0.079366,
     "end_time": "2021-10-28T01:22:32.296748",
     "exception": false,
     "start_time": "2021-10-28T01:22:32.217382",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```yaml\n",
    "# Content of fallback.yaml\n",
    "serializer: custom.my_fallback_serializer\n",
    "unserializer: custom.my_fallback_unserializer\n",
    "\n",
    "tasks:\n",
    "  - source: tasks.first\n",
    "    product: output/one_dict\n",
    "  \n",
    "  - source: tasks.second\n",
    "    product:\n",
    "        another: output/another_dict.json\n",
    "        final: output/final_dict.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272e9630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:32.469775Z",
     "iopub.status.busy": "2021-10-28T01:22:32.464474Z",
     "iopub.status.idle": "2021-10-28T01:22:42.829574Z",
     "shell.execute_reply": "2021-10-28T01:22:42.830027Z"
    },
    "papermill": {
     "duration": 10.459149,
     "end_time": "2021-10-28T01:22:42.830254",
     "exception": false,
     "start_time": "2021-10-28T01:22:32.371105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    Ran?      Elapsed (s)    Percentage\n",
      "------  ------  -------------  ------------\n",
      "first   True         0.002278       56.8505\n",
      "second  True         0.001729       43.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building task 'second': 100%|██████████| 2/2 [00:06<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build --entry-point fallback.yaml --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaaef26",
   "metadata": {
    "papermill": {
     "duration": 0.085264,
     "end_time": "2021-10-28T01:22:42.996578",
     "exception": false,
     "start_time": "2021-10-28T01:22:42.911314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's print the JSON files to verify their contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f15b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:43.183381Z",
     "iopub.status.busy": "2021-10-28T01:22:43.182245Z",
     "iopub.status.idle": "2021-10-28T01:22:43.248682Z",
     "shell.execute_reply": "2021-10-28T01:22:43.249864Z"
    },
    "papermill": {
     "duration": 0.161117,
     "end_time": "2021-10-28T01:22:43.250102",
     "exception": false,
     "start_time": "2021-10-28T01:22:43.088985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": 3, \"b\": 2}"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat output/another_dict.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefe4540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:43.434417Z",
     "iopub.status.busy": "2021-10-28T01:22:43.433201Z",
     "iopub.status.idle": "2021-10-28T01:22:43.494818Z",
     "shell.execute_reply": "2021-10-28T01:22:43.495565Z"
    },
    "papermill": {
     "duration": 0.158837,
     "end_time": "2021-10-28T01:22:43.495957",
     "exception": false,
     "start_time": "2021-10-28T01:22:43.337120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": 100, \"b\": 200}"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat output/final_dict.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d4e80",
   "metadata": {
    "papermill": {
     "duration": 0.081537,
     "end_time": "2021-10-28T01:22:43.661055",
     "exception": false,
     "start_time": "2021-10-28T01:22:43.579518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Using default serializers\n",
    "\n",
    "Ploomber comes with a few convenient serialization functions to write more succint serializers. We can request the use of such default serializers using the `defaults` argument, which takes a list of extensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497832b",
   "metadata": {
    "papermill": {
     "duration": 0.07608,
     "end_time": "2021-10-28T01:22:43.815101",
     "exception": false,
     "start_time": "2021-10-28T01:22:43.739021",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```python\n",
    "# Content of custom.py\n",
    "\n",
    "from ploomber.io import serializer, unserializer\n",
    "\n",
    "\n",
    "@serializer(fallback=True, defaults=['.json'])\n",
    "def my_defaults_serializer(obj, product):\n",
    "    pass\n",
    "\n",
    "\n",
    "@unserializer(fallback=True, defaults=['.json'])\n",
    "def my_defaults_unserializer(product):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1814a186",
   "metadata": {
    "papermill": {
     "duration": 0.080539,
     "end_time": "2021-10-28T01:22:43.972586",
     "exception": false,
     "start_time": "2021-10-28T01:22:43.892047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we're asking to dispatch `.json` products and use `pickle` for all other extensions, the same as we did for the previous examples, except this time, we don't have to pass the mapping argument to the decorators.\n",
    "\n",
    "`defaults` support:\n",
    "\n",
    "1. `.json`: the returned object must be JSON-serializable (e.g., a list or a dictionary)\n",
    "2. `.txt`: the returned object must be a string\n",
    "3. `.csv`: the returned object must be a `pandas.DataFrame`\n",
    "4. `.parquet`: the returned object must be a `pandas.DataFrame,` and a parquet library should be installed (such as `pyarrow`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f2f79",
   "metadata": {
    "papermill": {
     "duration": 0.084209,
     "end_time": "2021-10-28T01:22:44.136744",
     "exception": false,
     "start_time": "2021-10-28T01:22:44.052535",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```yaml\n",
    "# Content of defaults.yaml\n",
    "serializer: custom.my_defaults_serializer\n",
    "unserializer: custom.my_defaults_unserializer\n",
    "\n",
    "tasks:\n",
    "  - source: tasks.first\n",
    "    product: output/one_dict\n",
    "  \n",
    "  - source: tasks.second\n",
    "    product:\n",
    "        another: output/another_dict.json\n",
    "        final: output/final_dict.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c9d35d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:44.296333Z",
     "iopub.status.busy": "2021-10-28T01:22:44.295309Z",
     "iopub.status.idle": "2021-10-28T01:22:55.078165Z",
     "shell.execute_reply": "2021-10-28T01:22:55.078711Z"
    },
    "papermill": {
     "duration": 10.864708,
     "end_time": "2021-10-28T01:22:55.078922",
     "exception": false,
     "start_time": "2021-10-28T01:22:44.214214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    Ran?      Elapsed (s)    Percentage\n",
      "------  ------  -------------  ------------\n",
      "first   True         0.001148       39.1675\n",
      "second  True         0.001783       60.8325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building task 'second': 100%|██████████| 2/2 [00:07<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build --entry-point defaults.yaml --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d583241",
   "metadata": {
    "papermill": {
     "duration": 0.086669,
     "end_time": "2021-10-28T01:22:55.263135",
     "exception": false,
     "start_time": "2021-10-28T01:22:55.176466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's print the JSON files to verify their contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16e609f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:55.442212Z",
     "iopub.status.busy": "2021-10-28T01:22:55.441575Z",
     "iopub.status.idle": "2021-10-28T01:22:55.500029Z",
     "shell.execute_reply": "2021-10-28T01:22:55.500656Z"
    },
    "papermill": {
     "duration": 0.152266,
     "end_time": "2021-10-28T01:22:55.500895",
     "exception": false,
     "start_time": "2021-10-28T01:22:55.348629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": 3, \"b\": 2}"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat output/another_dict.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aabe867c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T01:22:55.672185Z",
     "iopub.status.busy": "2021-10-28T01:22:55.671308Z",
     "iopub.status.idle": "2021-10-28T01:22:55.733967Z",
     "shell.execute_reply": "2021-10-28T01:22:55.734496Z"
    },
    "papermill": {
     "duration": 0.151904,
     "end_time": "2021-10-28T01:22:55.734753",
     "exception": false,
     "start_time": "2021-10-28T01:22:55.582849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": 100, \"b\": 200}"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat output/final_dict.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc99fe3",
   "metadata": {
    "papermill": {
     "duration": 0.087874,
     "end_time": "2021-10-28T01:22:55.905248",
     "exception": false,
     "start_time": "2021-10-28T01:22:55.817374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Wrapping up\n",
    "\n",
    "Configuring a `serializer` and `unserializer` in your `pipeline.yaml` is optional, but it helps you quickly generate a fully in-memory pipeline for serving predictions.\n",
    "\n",
    "If you want to learn more about in-memory pipelines, check out the [following guide](https://docs.ploomber.io/en/latest/deployment/online.html).\n",
    "\n",
    "For a complete example showing how to manage a training and a serving pipeline, and deploy it as a Flask API, [click here](https://github.com/ploomber/projects/tree/master/templates/ml-online)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 64.175946,
   "end_time": "2021-10-28T01:22:56.210028",
   "environment_variables": {},
   "exception": null,
   "input_path": "guides/serialization/_build/readme_preprocessed.ipynb",
   "output_path": "guides/serialization/README.ipynb",
   "parameters": {},
   "start_time": "2021-10-28T01:21:52.034082",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
