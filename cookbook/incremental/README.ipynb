{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a009c235",
   "metadata": {
    "papermill": {
     "duration": 0.008107,
     "end_time": "2022-11-16T14:35:04.353958",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.345851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To run this locally, [install Ploomber](https://docs.ploomber.io/en/latest/get-started/quick-start.html) and execute: `ploomber examples -n cookbook/incremental`\n",
    "\n",
    "Questions? [Ask us on Slack.](https://ploomber.io/community/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83313b68",
   "metadata": {
    "papermill": {
     "duration": 0.003381,
     "end_time": "2022-11-16T14:35:04.361959",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.358578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Incremental processing\n",
    "\n",
    "<!-- start description -->\n",
    "A pipeline that processes new records from a database and uploads them.\n",
    "<!-- end description -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf658c",
   "metadata": {
    "papermill": {
     "duration": 0.003431,
     "end_time": "2022-11-16T14:35:04.368753",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.365322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A common scenario is to have a pipeline that processes records incrementally. For example, we might load data from a data warehouse, process all historical records one, and store results in another table. However, when running the pipeline again, we might want to process new records only, since it'd be time consuming to process all records again.\n",
    "\n",
    "To achieve so, we can add a dynamic parameter to our pipeline to return the index of the latest processed record. Let's look at the `pipeline.yaml`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a37c80",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.003548,
     "end_time": "2022-11-16T14:35:04.375734",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.372186",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```yaml\n",
    "# Content of pipeline.yaml\n",
    "tasks:\n",
    "  - source: tasks/load.py\n",
    "    product:\n",
    "      nb: output/load.ipynb\n",
    "      data: output/raw.csv\n",
    "    params:\n",
    "      index: \n",
    "        dotted_path: params::get_index\n",
    "        path_to_index: '{{root}}/index.json'\n",
    "\n",
    "      path_to_db: '{{root}}/data.db'\n",
    "\n",
    "    on_finish: hooks.check_if_new_records\n",
    "\n",
    "  - source: tasks/process.py\n",
    "    product:\n",
    "      nb: output/process.ipynb\n",
    "      data: output/processed.csv\n",
    "\n",
    "  - source: tasks/upload.py\n",
    "    product:\n",
    "      nb: output/upload.ipynb\n",
    "    params:\n",
    "      path_to_db: '{{root}}/data.db'\n",
    "\n",
    "    on_finish:\n",
    "      dotted_path: hooks.store_index\n",
    "      path_to_index: '{{root}}/index.json'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a174167",
   "metadata": {
    "papermill": {
     "duration": 0.003896,
     "end_time": "2022-11-16T14:35:04.383496",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.379600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The first task (`tasks/load.py`) has a dynamic parameter (`params::get_index`). Whenever Ploomber runs your pipeline, it'll import `params.py`, call `get_index()` and assign the returned value to the `index` parameter in the task.\n",
    "\n",
    "Let's look at `params.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080017c",
   "metadata": {
    "papermill": {
     "duration": 0.003087,
     "end_time": "2022-11-16T14:35:04.390126",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.387039",
     "status": "completed"
    },
    "region_name": "md",
    "tags": []
   },
   "source": [
    "```python\n",
    "# Content of params.py\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_index(path_to_index):\n",
    "    path = Path(path_to_index)\n",
    "\n",
    "    if not path.exists():\n",
    "        return -1\n",
    "\n",
    "    index = json.loads(path.read_text())\n",
    "    return index['latest']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e45ce",
   "metadata": {
    "papermill": {
     "duration": 0.003291,
     "end_time": "2022-11-16T14:35:04.396535",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.393244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can see that it loads the parameter from an `index.json` file; however, you can store the parameter anywhere you want.\n",
    "\n",
    "Let's now create a sample database and insert 100 records to a table named `numbers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7863f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:04.406387Z",
     "iopub.status.busy": "2022-11-16T14:35:04.405970Z",
     "iopub.status.idle": "2022-11-16T14:35:04.470364Z",
     "shell.execute_reply": "2022-11-16T14:35:04.468919Z"
    },
    "papermill": {
     "duration": 0.071812,
     "end_time": "2022-11-16T14:35:04.473127",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.401315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# clean up data and parameters in case we have anything\n",
    "rm -f data.db index.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59210ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:04.484627Z",
     "iopub.status.busy": "2022-11-16T14:35:04.484147Z",
     "iopub.status.idle": "2022-11-16T14:35:05.187689Z",
     "shell.execute_reply": "2022-11-16T14:35:05.186356Z"
    },
    "papermill": {
     "duration": 0.71274,
     "end_time": "2022-11-16T14:35:05.190348",
     "exception": false,
     "start_time": "2022-11-16T14:35:04.477608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending 100 records...\n",
      "Index range: 1, 100\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# create database and insert 100 rows\n",
    "python insert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d9e6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:05.199501Z",
     "iopub.status.busy": "2022-11-16T14:35:05.199131Z",
     "iopub.status.idle": "2022-11-16T14:35:05.299263Z",
     "shell.execute_reply": "2022-11-16T14:35:05.297867Z"
    },
    "papermill": {
     "duration": 0.107696,
     "end_time": "2022-11-16T14:35:05.301744",
     "exception": false,
     "start_time": "2022-11-16T14:35:05.194048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers has 100 rows\n",
      "plus_one table does not exist\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# count rows in the table\n",
    "python count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dec4d4",
   "metadata": {
    "papermill": {
     "duration": 0.00355,
     "end_time": "2022-11-16T14:35:05.309547",
     "exception": false,
     "start_time": "2022-11-16T14:35:05.305997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's run the pipeline. Our tasks will load all unprocessed records from the `numbers` table, transform the data and store the output in the `plus_one` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2096318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:05.318602Z",
     "iopub.status.busy": "2022-11-16T14:35:05.318213Z",
     "iopub.status.idle": "2022-11-16T14:35:18.100389Z",
     "shell.execute_reply": "2022-11-16T14:35:18.099351Z"
    },
    "papermill": {
     "duration": 12.78986,
     "end_time": "2022-11-16T14:35:18.102888",
     "exception": false,
     "start_time": "2022-11-16T14:35:05.313028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ploomber.dag.dag:Building DAG DAG(\"incremental\")\n",
      "Building task 'load':   0%|          | 0/3 [00:00<?, ?it/s]INFO:ploomber.tasks.abc.NotebookRunner:Starting execution: NotebookRunner: load -> MetaProduct({'data': File('output/raw.csv'), 'nb': File('output/load.ipynb')})\n",
      "INFO:papermill:Input Notebook:  /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpg59y4re6.ipynb\n",
      "INFO:papermill:Output Notebook: /Users/Edu/dev/projects-ploomber/cookbook/incremental/output/load.ipynb\n",
      "\n",
      "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]INFO:papermill:Executing notebook with kernel: python3\n",
      "\n",
      "Executing:  17%|█▋        | 1/6 [00:01<00:08,  1.62s/cell]\n",
      "Executing: 100%|██████████| 6/6 [00:02<00:00,  2.41cell/s]\n",
      "INFO:ploomber.tasks.abc.NotebookRunner:Done. Operation took 2.5 seconds\n",
      "Building task 'process':  33%|███▎      | 1/3 [00:02<00:05,  2.52s/it]INFO:ploomber.tasks.abc.NotebookRunner:Starting execution: NotebookRunner: process -> MetaProduct({'data': File('output/processed.csv'), 'nb': File('output/process.ipynb')})\n",
      "INFO:papermill:Input Notebook:  /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmptjt8evwa.ipynb\n",
      "INFO:papermill:Output Notebook: /Users/Edu/dev/projects-ploomber/cookbook/incremental/output/process.ipynb\n",
      "\n",
      "Executing:   0%|          | 0/7 [00:00<?, ?cell/s]INFO:papermill:Executing notebook with kernel: python3\n",
      "\n",
      "Executing:  14%|█▍        | 1/7 [00:01<00:09,  1.53s/cell]\n",
      "Executing: 100%|██████████| 7/7 [00:02<00:00,  2.92cell/s]\n",
      "INFO:ploomber.tasks.abc.NotebookRunner:Done. Operation took 2.4 seconds\n",
      "Building task 'upload':  67%|██████▋   | 2/3 [00:04<00:02,  2.46s/it] INFO:ploomber.tasks.abc.NotebookRunner:Starting execution: NotebookRunner: upload -> MetaProduct({'nb': File('output/upload.ipynb')})\n",
      "INFO:papermill:Input Notebook:  /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpi7k84n0v.ipynb\n",
      "INFO:papermill:Output Notebook: /Users/Edu/dev/projects-ploomber/cookbook/incremental/output/upload.ipynb\n",
      "\n",
      "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]INFO:papermill:Executing notebook with kernel: python3\n",
      "\n",
      "Executing:  17%|█▋        | 1/6 [00:01<00:06,  1.32s/cell]\n",
      "Executing: 100%|██████████| 6/6 [00:02<00:00,  2.76cell/s]\n",
      "INFO:ploomber.tasks.abc.NotebookRunner:Done. Operation took 2.2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing index: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building task 'upload': 100%|██████████| 3/3 [00:07<00:00,  2.38s/it]\n",
      "/Users/Edu/miniconda3/envs/projects/lib/python3.9/site-packages/ploomber/executors/serial.py:187: UserWarning: \n",
      "=========================== DAG build with warnings ============================\n",
      "- NotebookRunner: load -> MetaProduct({'data': File('output/raw.csv'), 'nb': File('output/load.ipynb')}) -\n",
      "----- /Users/Edu/dev/projects-ploomber/cookbook/incremental/tasks/load.py ------\n",
      ":10:1: 'json' imported but unused\n",
      ":11:1: 'pathlib.Path' imported but unused\n",
      "=============================== Summary (1 task) ===============================\n",
      "NotebookRunner: load -> MetaProduct({'data': File('output/raw.csv'), 'nb': File('output/load.ipynb')})\n",
      "=========================== DAG build with warnings ============================\n",
      "\n",
      "  warnings.warn(str(warnings_all))\n",
      "INFO:ploomber.dag.dag: DAG report:\n",
      "name     Ran?      Elapsed (s)    Percentage\n",
      "-------  ------  -------------  ------------\n",
      "load     True          2.5057        35.2447\n",
      "process  True          2.41283       33.9385\n",
      "upload   True          2.1909        30.8168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name     Ran?      Elapsed (s)    Percentage\n",
      "-------  ------  -------------  ------------\n",
      "load     True          2.5057        35.2447\n",
      "process  True          2.41283       33.9385\n",
      "upload   True          2.1909        30.8168\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ploomber build --log info --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc1007",
   "metadata": {
    "papermill": {
     "duration": 0.006469,
     "end_time": "2022-11-16T14:35:18.116911",
     "exception": false,
     "start_time": "2022-11-16T14:35:18.110442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check the table counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4678485b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:18.133335Z",
     "iopub.status.busy": "2022-11-16T14:35:18.132787Z",
     "iopub.status.idle": "2022-11-16T14:35:18.237825Z",
     "shell.execute_reply": "2022-11-16T14:35:18.236492Z"
    },
    "papermill": {
     "duration": 0.11631,
     "end_time": "2022-11-16T14:35:18.240385",
     "exception": false,
     "start_time": "2022-11-16T14:35:18.124075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers has 100 rows\n",
      "plus_one has 100 rows\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999a7a2",
   "metadata": {
    "papermill": {
     "duration": 0.006653,
     "end_time": "2022-11-16T14:35:18.253794",
     "exception": false,
     "start_time": "2022-11-16T14:35:18.247141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Great, our pipeline processed the existing 100 rows in `numbers` and stored the results in the `plus_one` table.\n",
    "\n",
    "Let's add another 100 rows to the `numbers` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d07dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:18.269829Z",
     "iopub.status.busy": "2022-11-16T14:35:18.269125Z",
     "iopub.status.idle": "2022-11-16T14:35:18.986018Z",
     "shell.execute_reply": "2022-11-16T14:35:18.984949Z"
    },
    "papermill": {
     "duration": 0.727251,
     "end_time": "2022-11-16T14:35:18.988585",
     "exception": false,
     "start_time": "2022-11-16T14:35:18.261334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending 100 records...\n",
      "Index range: 101, 200\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python insert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea432820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:19.003655Z",
     "iopub.status.busy": "2022-11-16T14:35:19.003234Z",
     "iopub.status.idle": "2022-11-16T14:35:19.103450Z",
     "shell.execute_reply": "2022-11-16T14:35:19.102286Z"
    },
    "papermill": {
     "duration": 0.11123,
     "end_time": "2022-11-16T14:35:19.106007",
     "exception": false,
     "start_time": "2022-11-16T14:35:18.994777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers has 200 rows\n",
      "plus_one has 100 rows\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b482b",
   "metadata": {
    "papermill": {
     "duration": 0.007581,
     "end_time": "2022-11-16T14:35:19.120340",
     "exception": false,
     "start_time": "2022-11-16T14:35:19.112759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Process the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00cd9f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:19.135854Z",
     "iopub.status.busy": "2022-11-16T14:35:19.135489Z",
     "iopub.status.idle": "2022-11-16T14:35:29.963581Z",
     "shell.execute_reply": "2022-11-16T14:35:29.962621Z"
    },
    "papermill": {
     "duration": 10.838992,
     "end_time": "2022-11-16T14:35:29.965990",
     "exception": false,
     "start_time": "2022-11-16T14:35:19.126998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ploomber.dag.dag:Building DAG DAG(\"incremental\")\n",
      "Building task 'load':   0%|          | 0/3 [00:00<?, ?it/s]INFO:ploomber.tasks.abc.NotebookRunner:Starting execution: NotebookRunner: load -> MetaProduct({'data': File('output/raw.csv'), 'nb': File('output/load.ipynb')})\n",
      "INFO:papermill:Input Notebook:  /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmp8byixllc.ipynb\n",
      "INFO:papermill:Output Notebook: /Users/Edu/dev/projects-ploomber/cookbook/incremental/output/load.ipynb\n",
      "\n",
      "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]INFO:papermill:Executing notebook with kernel: python3\n",
      "\n",
      "Executing:  17%|█▋        | 1/6 [00:01<00:07,  1.48s/cell]\n",
      "Executing: 100%|██████████| 6/6 [00:02<00:00,  2.58cell/s]\n",
      "INFO:ploomber.tasks.abc.NotebookRunner:Done. Operation took 2.3 seconds\n",
      "Building task 'process':  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]INFO:ploomber.tasks.abc.NotebookRunner:Starting execution: NotebookRunner: process -> MetaProduct({'data': File('output/processed.csv'), 'nb': File('output/process.ipynb')})\n",
      "INFO:papermill:Input Notebook:  /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpvko1asee.ipynb\n",
      "INFO:papermill:Output Notebook: /Users/Edu/dev/projects-ploomber/cookbook/incremental/output/process.ipynb\n",
      "\n",
      "Executing:   0%|          | 0/7 [00:00<?, ?cell/s]INFO:papermill:Executing notebook with kernel: python3\n",
      "\n",
      "Executing:  14%|█▍        | 1/7 [00:01<00:07,  1.27s/cell]\n",
      "Executing: 100%|██████████| 7/7 [00:02<00:00,  3.32cell/s]\n",
      "INFO:ploomber.tasks.abc.NotebookRunner:Done. Operation took 2.1 seconds\n",
      "Building task 'upload':  67%|██████▋   | 2/3 [00:04<00:02,  2.22s/it] INFO:ploomber.tasks.abc.NotebookRunner:Starting execution: NotebookRunner: upload -> MetaProduct({'nb': File('output/upload.ipynb')})\n",
      "INFO:papermill:Input Notebook:  /var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpgzlo9f5v.ipynb\n",
      "INFO:papermill:Output Notebook: /Users/Edu/dev/projects-ploomber/cookbook/incremental/output/upload.ipynb\n",
      "\n",
      "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]INFO:papermill:Executing notebook with kernel: python3\n",
      "\n",
      "Executing:  17%|█▋        | 1/6 [00:01<00:07,  1.48s/cell]\n",
      "Executing: 100%|██████████| 6/6 [00:02<00:00,  2.59cell/s]\n",
      "INFO:ploomber.tasks.abc.NotebookRunner:Done. Operation took 2.3 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing index: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building task 'upload': 100%|██████████| 3/3 [00:06<00:00,  2.27s/it]\n",
      "/Users/Edu/miniconda3/envs/projects/lib/python3.9/site-packages/ploomber/executors/serial.py:187: UserWarning: \n",
      "=========================== DAG build with warnings ============================\n",
      "- NotebookRunner: load -> MetaProduct({'data': File('output/raw.csv'), 'nb': File('output/load.ipynb')}) -\n",
      "----- /Users/Edu/dev/projects-ploomber/cookbook/incremental/tasks/load.py ------\n",
      ":10:1: 'json' imported but unused\n",
      ":11:1: 'pathlib.Path' imported but unused\n",
      "=============================== Summary (1 task) ===============================\n",
      "NotebookRunner: load -> MetaProduct({'data': File('output/raw.csv'), 'nb': File('output/load.ipynb')})\n",
      "=========================== DAG build with warnings ============================\n",
      "\n",
      "  warnings.warn(str(warnings_all))\n",
      "INFO:ploomber.dag.dag: DAG report:\n",
      "name     Ran?      Elapsed (s)    Percentage\n",
      "-------  ------  -------------  ------------\n",
      "load     True          2.33977       34.4733\n",
      "process  True          2.11967       31.2303\n",
      "upload   True          2.32776       34.2964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name     Ran?      Elapsed (s)    Percentage\n",
      "-------  ------  -------------  ------------\n",
      "load     True          2.33977       34.4733\n",
      "process  True          2.11967       31.2303\n",
      "upload   True          2.32776       34.2964\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ploomber build --log info --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1003bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:29.989922Z",
     "iopub.status.busy": "2022-11-16T14:35:29.989309Z",
     "iopub.status.idle": "2022-11-16T14:35:30.095349Z",
     "shell.execute_reply": "2022-11-16T14:35:30.094356Z"
    },
    "papermill": {
     "duration": 0.122654,
     "end_time": "2022-11-16T14:35:30.098081",
     "exception": false,
     "start_time": "2022-11-16T14:35:29.975427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers has 200 rows\n",
      "plus_one has 200 rows\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e91945",
   "metadata": {
    "papermill": {
     "duration": 0.008865,
     "end_time": "2022-11-16T14:35:30.116056",
     "exception": false,
     "start_time": "2022-11-16T14:35:30.107191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now our `plus_one` table has 200 records, and the last execution only processed 100 rows. Note that if we run the pipeline again, it'll stop after running the `load` task since there are no records to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e67544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:30.135936Z",
     "iopub.status.busy": "2022-11-16T14:35:30.135545Z",
     "iopub.status.idle": "2022-11-16T14:35:36.653134Z",
     "shell.execute_reply": "2022-11-16T14:35:36.652067Z"
    },
    "papermill": {
     "duration": 6.530691,
     "end_time": "2022-11-16T14:35:36.655479",
     "exception": false,
     "start_time": "2022-11-16T14:35:30.124788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building task 'load':   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Executing:   0%|          | 0/6 [00:00<?, ?cell/s]\n",
      "Executing:  17%|█▋        | 1/6 [00:01<00:07,  1.47s/cell]\n",
      "Executing: 100%|██████████| 6/6 [00:02<00:00,  2.55cell/s]\n",
      "Building task 'load': 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ploomber build --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73c2012d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T14:35:36.677919Z",
     "iopub.status.busy": "2022-11-16T14:35:36.677280Z",
     "iopub.status.idle": "2022-11-16T14:35:36.788622Z",
     "shell.execute_reply": "2022-11-16T14:35:36.787599Z"
    },
    "papermill": {
     "duration": 0.125816,
     "end_time": "2022-11-16T14:35:36.791202",
     "exception": false,
     "start_time": "2022-11-16T14:35:36.665386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers has 200 rows\n",
      "plus_one has 200 rows\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python count.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.559094,
   "end_time": "2022-11-16T14:35:37.028326",
   "environment_variables": {},
   "exception": null,
   "input_path": "cookbook/incremental/_build/readme_preprocessed.ipynb",
   "output_path": "cookbook/incremental/README.ipynb",
   "parameters": {},
   "start_time": "2022-11-16T14:35:02.469232",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
